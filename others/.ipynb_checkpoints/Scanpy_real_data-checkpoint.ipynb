{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scanpy/api/__init__.py:7: FutureWarning: \n",
      "\n",
      "In a future version of Scanpy, `scanpy.api` will be removed.\n",
      "Simply use `import scanpy as sc` and `import scanpy.external as sce` instead.\n",
      "\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gnn_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69a294cbaa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgnn_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gnn_utils'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import glob2\n",
    "import gnn_utils\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = [x for x in os.listdir('../dataset') if x.startswith(\".\")== False]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"dataset\", \"scanpy\", \"run\"])\n",
    "for run in range(1):\n",
    "    print(df.shape)\n",
    "    for dataset in files:\n",
    "        print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "        X, Y, gene_names = gnn_utils.get_sczi_data(path, dataset)\n",
    "\n",
    "        \n",
    "        print(np.where(X ==0)[0].shape[0]/(X.shape[0]*X.shape[1]))\n",
    "        X = np.ceil(X).astype(np.int)\n",
    "        adata = sc.AnnData(X)\n",
    "        adata.obs['Group'] = Y\n",
    "        adata.var_names_make_unique()\n",
    "\n",
    "        sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "\n",
    "        sc.pp.log1p(adata)\n",
    "\n",
    "        sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "        adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "        sc.pp.scale(adata, max_value=10)\n",
    "\n",
    "        sc.tl.pca(adata, svd_solver='arpack')\n",
    "\n",
    "        sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "\n",
    "        sc.tl.umap(adata)\n",
    "\n",
    "        sc.tl.leiden(adata)\n",
    "\n",
    "        pred = adata.obs['leiden'].to_list()\n",
    "        pred = [int(x) for x in pred]\n",
    "        ari = adjusted_rand_score(Y, pred)\n",
    "        df.loc[df.shape[0]] = [dataset, ari, run]\n",
    "        print(f\"ARI {ari}\")\n",
    "        df.to_pickle(f\"{path}output/pickle_results/real_data_scanpy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
