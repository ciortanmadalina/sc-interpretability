{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d17d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = datasets.FashionMNIST(\n",
    "#     root='./data',\n",
    "#     train=True, \n",
    "#     download=True,\n",
    "#     transform=transform\n",
    "# )\n",
    "# testset = datasets.FashionMNIST(\n",
    "#     root='./data',\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=transform\n",
    "# )\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    root='./data1',\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root='./data1',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8279ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "def make_dir():\n",
    "    image_dir = 'FashionMNIST_Images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "def save_decoded_image(img, epoch):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, './FashionMNIST_Images/linear_ae_image{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8310b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         # encoder\n",
    "#         self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "#         self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "#         self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "#         self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "#         self.enc5 = nn.Linear(in_features=32, out_features=16)\n",
    "#         # decoder \n",
    "#         self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "#         self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "#         self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "#         self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "#         self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.enc1(x))\n",
    "#         x = F.relu(self.enc2(x))\n",
    "#         x = F.relu(self.enc3(x))\n",
    "#         x = F.relu(self.enc4(x))\n",
    "#         code = F.relu(self.enc5(x))\n",
    "#         x = F.relu(self.dec1(code))\n",
    "#         x = F.relu(self.dec2(x))\n",
    "#         x = F.relu(self.dec3(x))\n",
    "#         x = F.relu(self.dec4(x))\n",
    "#         x = F.relu(self.dec5(x))\n",
    "#         return x, code\n",
    "    \n",
    "    \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=16))\n",
    "\n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "    def forward(self, x):\n",
    "\n",
    "        code = self.encoder(x)\n",
    "        x = F.relu(self.dec1(code))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "        return x, code\n",
    "net = Autoencoder()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf48736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35514e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd67075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            img, _ = data\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs , code= net(img)\n",
    "            loss = criterion(outputs, img)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        loss = running_loss / len(trainloader)\n",
    "        train_loss.append(loss)\n",
    "        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, NUM_EPOCHS, loss))\n",
    "        if epoch % 5 == 0:\n",
    "            save_decoded_image(outputs.cpu().data, epoch)\n",
    "    return train_loss\n",
    "def test_image_reconstruction(net, testloader):\n",
    "     for batch in testloader:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        outputs = net(img)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        save_image(outputs, 'fashionmnist_reconstruction.png')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fe794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "print(device)\n",
    "# load the neural network onto the device\n",
    "net.to(device)\n",
    "make_dir()\n",
    "# train the network\n",
    "train_loss = train(net, trainloader, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ActivationsAndGradients:\n",
    "#     \"\"\" Class for extracting activations and\n",
    "#     registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "#     def __init__(self, model, target_layer):\n",
    "#         self.model = model\n",
    "#         self.gradients = []\n",
    "#         self.activations = []\n",
    "#         print(target_layer)\n",
    "#         target_layer.register_forward_hook(self.save_activation)\n",
    "#         target_layer.register_backward_hook(self.save_gradient)\n",
    "\n",
    "#     def save_activation(self, module, input, output):\n",
    "#         print(f\"save input {len(input)}, output {output.shape}\")\n",
    "#         activation = output\n",
    "#         self.activations.append(activation.cpu().detach())\n",
    "\n",
    "#     def save_gradient(self, module, grad_input, grad_output):\n",
    "#         print(f\"grad input {grad_input[0].shape}, output {grad_output[0].shape}\")\n",
    "#         # Gradients are computed in reverse order\n",
    "#         grad = grad_output[0]\n",
    "#         self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         self.gradients = []\n",
    "#         self.activations = []        \n",
    "#         return self.model(x)\n",
    "\n",
    "# activations_and_grads = ActivationsAndGradients(net,net.encoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_code = []\n",
    "all_labels = []\n",
    "for batch in trainloader:\n",
    "    img, label = batch\n",
    "    img = img.to(device)\n",
    "    img = img.view(img.size(0), -1)\n",
    "    outputs, code = net(img)\n",
    "    all_code.extend(code.detach().cpu().numpy())\n",
    "    all_labels.extend(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bec2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_code = []\n",
    "# all_labels = []\n",
    "# for batch in testloader:\n",
    "#     img, label = batch\n",
    "#     img = img.to(device)\n",
    "#     img = img.view(img.size(0), -1)\n",
    "#     outputs, code = net(img)\n",
    "#     all_code.extend(code.detach().cpu().numpy())\n",
    "#     all_labels.extend(label.numpy())\n",
    "#     outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = np.stack(all_labels)\n",
    "all_code= np.stack(all_code)\n",
    "all_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f576d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3dfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f176f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(all_labels, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainloader:\n",
    "    img, label = data\n",
    "    img = img[:1]\n",
    "    label = label[:1]\n",
    "    print(f\"Label : {label}\")\n",
    "    img = img.to(device)\n",
    "    img = img.view(img.size(0), -1)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ef72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "outputs , code= net(img)\n",
    "loss = criterion(outputs, img)\n",
    "loss.backward(retain_graph = True)\n",
    "\n",
    "w = net.encoder[0].weight.detach().cpu().mean(dim=0).numpy()\n",
    "g = net.encoder[0].weight.grad.detach().cpu().mean(dim=0).numpy()\n",
    "wa = (net.encoder[0].weight*net.encoder[0].weight.grad).detach().cpu().mean(dim=0).numpy()\n",
    "plt.imshow(img[0].cpu().numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d33dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "outputs , code= net(img)\n",
    "pred = kmeans.predict(code.detach().cpu().numpy())\n",
    "center = torch.FloatTensor(kmeans.cluster_centers_[pred[0]].reshape(1, -1)).to(device)\n",
    "mse = nn.MSELoss()\n",
    "loss1 =mse(code,center )\n",
    "loss1.backward(retain_graph = True)\n",
    "\n",
    "w1 = net.encoder[0].weight.detach().cpu().mean(dim=0).numpy()\n",
    "g1 = net.encoder[0].weight.grad.detach().cpu().mean(dim=0).numpy()\n",
    "wa1 = (net.encoder[0].weight*net.encoder[0].weight.grad).detach().cpu().mean(dim=0).numpy()\n",
    "plt.imshow(img[0].cpu().numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472a073",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g1s = []\n",
    "wa1s = []\n",
    "for c in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs , code= net(img)\n",
    "    pred = kmeans.predict(code.detach().cpu().numpy())\n",
    "    print(f\"Correct cluster = {pred}\")\n",
    "    center = torch.FloatTensor(kmeans.cluster_centers_[c].reshape(1, -1)).to(device)\n",
    "    mse = nn.MSELoss()\n",
    "    loss1 =mse(code,center )\n",
    "    loss1.backward(retain_graph = True)\n",
    "    \n",
    "    w1 = net.encoder[0].weight.detach().cpu().mean(dim=0).numpy()\n",
    "    g1 = net.encoder[0].weight.grad.detach().cpu().mean(dim=0).numpy()\n",
    "    wa1 = (net.encoder[0].weight*net.encoder[0].weight.grad).detach().cpu().mean(dim=0).numpy()\n",
    "\n",
    "    g1s.append(g1)\n",
    "    wa1s.append(wa1)\n",
    "    plt.figure(figsize = (8, 3))\n",
    "    plt.subplot(121)\n",
    "    plt.title(f\"{c} cluster WA cluster MSE\")\n",
    "    plt.imshow(wa1.reshape(28, 28), cmap = \"coolwarm\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"gradient cluster MSE\")\n",
    "    plt.imshow(g1.reshape(28, 28), cmap = \"coolwarm\")\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550fc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(321)\n",
    "plt.title(\"gradient MSE\")\n",
    "plt.imshow(g.reshape(28, 28), cmap = \"coolwarm\")\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.title(\"gradient cluster MSE\")\n",
    "plt.imshow(g1.reshape(28, 28), cmap = \"coolwarm\")\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.title(\"WA MSE\")\n",
    "plt.imshow(wa.reshape(28, 28), cmap = \"coolwarm\")\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.title(\"WA cluster MSE\")\n",
    "plt.imshow(wa1.reshape(28, 28), cmap = \"coolwarm\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197b73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54336f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ab015",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c = all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ad28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
